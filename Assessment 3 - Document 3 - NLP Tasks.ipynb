{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pandas version is 0.25.1.\n",
      "The nltk version is 3.4.5.\n",
      "The scikit-learn version is 0.21.3.\n"
     ]
    }
   ],
   "source": [
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Sklearn\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download()\n",
    "\n",
    "\n",
    "print('The pandas version is {}.'.format(pd.__version__))\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uri</th>\n",
       "      <th>article_category</th>\n",
       "      <th>article_text</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>/news/2021-11-24/afl-carlton-ceo-brian-cook-te...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Carlton chief executive Brian Cook has tested...</td>\n",
       "      <td>Carlton AFL boss returns positive COVID test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>/news/2021-11-24/afl-national-draft-kangaroos-...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Outstanding South Australian prospect Jason H...</td>\n",
       "      <td>Kangaroos take Horne-Francis with number one s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>/news/2021-11-24/shaun-murphy-amateurs-not-pla...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Professional snooker player Shaun Murphy says...</td>\n",
       "      <td>Former champion says amateur snooker players s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>/news/2021-11-24/teen-star-sophie-dwyer-headli...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Giants goal-attack Sophie Dwyer has been elev...</td>\n",
       "      <td>Rising star Sophie Dwyer earns call-up to Aust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>/news/2021-11-24/wbbl-brisbane-heat-vs-adelaid...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Adelaide Strikers spinner Amanda-Jade Welling...</td>\n",
       "      <td>Adelaide Strikers stay alive in WBBL finals wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 uri article_category  \\\n",
       "0  /news/2021-11-24/afl-carlton-ceo-brian-cook-te...            sport   \n",
       "1  /news/2021-11-24/afl-national-draft-kangaroos-...            sport   \n",
       "2  /news/2021-11-24/shaun-murphy-amateurs-not-pla...            sport   \n",
       "3  /news/2021-11-24/teen-star-sophie-dwyer-headli...            sport   \n",
       "4  /news/2021-11-24/wbbl-brisbane-heat-vs-adelaid...            sport   \n",
       "\n",
       "                                        article_text  \\\n",
       "0   Carlton chief executive Brian Cook has tested...   \n",
       "1   Outstanding South Australian prospect Jason H...   \n",
       "2   Professional snooker player Shaun Murphy says...   \n",
       "3   Giants goal-attack Sophie Dwyer has been elev...   \n",
       "4   Adelaide Strikers spinner Amanda-Jade Welling...   \n",
       "\n",
       "                                         description  \n",
       "0       Carlton AFL boss returns positive COVID test  \n",
       "1  Kangaroos take Horne-Francis with number one s...  \n",
       "2  Former champion says amateur snooker players s...  \n",
       "3  Rising star Sophie Dwyer earns call-up to Aust...  \n",
       "4  Adelaide Strikers stay alive in WBBL finals wi...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load cleaned csv file\n",
    "articles_df = pd.read_csv(\"abc_articles_df.csv\", sep='|', encoding='utf-16')\n",
    "articles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uri</th>\n",
       "      <th>article_text</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>business</td>\n",
       "      <td>118</td>\n",
       "      <td>112</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sport</td>\n",
       "      <td>117</td>\n",
       "      <td>116</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  uri  article_text  description\n",
       "article_category                                \n",
       "business          118           112          118\n",
       "sport             117           116          117"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show counts and description\n",
    "articles_df.groupby(['article_category']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Tasks for both NLP\n",
    "\n",
    "Tasks include:\n",
    "    - \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uri</th>\n",
       "      <th>article_text_description</th>\n",
       "      <th>bag_of_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>business</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sport</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  uri  article_text_description  bag_of_words\n",
       "article_category                                             \n",
       "business          112                       112           112\n",
       "sport             116                       116           116"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine columns and drop uncessary columns\n",
    "\n",
    "articles_df.dropna(inplace=True) # Drop NA's\n",
    "\n",
    "# Combine text and description into 1 column\n",
    "articles_df['article_text_description'] = articles_df['article_text'].fillna('') + articles_df['description'].fillna('')\n",
    "\n",
    "articles_df.drop(columns=['description','article_text'], inplace=True) # Drop unnecesarry columns\n",
    "\n",
    "articles_df['bag_of_words'] = articles_df['article_text_description'] # Bag of words for further processing later\n",
    "\n",
    "\n",
    "# Show counts and description\n",
    "articles_df.groupby(['article_category']).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix unicode issues\n",
    "def fix_unicode_issues(df):  \n",
    "    df['article_text_description'] = df['article_text_description'].replace(u'â€”', u' ')\n",
    "    df['article_text_description'] = df['article_text_description'].replace(u'â€“', u' ')  \n",
    "    \n",
    "    return df\n",
    "\n",
    "articles_df = articles_df.apply(fix_unicode_issues, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP Task 1 will be a classificaction ML task to classify arcles between sport and business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing Punctuation and Numbers...\n",
      "Removing Stopwords...\n",
      "Applying Lemmatizing...\n",
      "Applying Stemming...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uri</th>\n",
       "      <th>article_category</th>\n",
       "      <th>article_text_description</th>\n",
       "      <th>bag_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>/news/2021-11-24/afl-carlton-ceo-brian-cook-te...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Carlton chief executive Brian Cook has tested...</td>\n",
       "      <td>carlton chief execut brian cook test posit for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>/news/2021-11-24/afl-national-draft-kangaroos-...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Outstanding South Australian prospect Jason H...</td>\n",
       "      <td>outstand south australian prospect jason selec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>/news/2021-11-24/shaun-murphy-amateurs-not-pla...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Professional snooker player Shaun Murphy says...</td>\n",
       "      <td>profession snooker player shaun murphi say ama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>/news/2021-11-24/teen-star-sophie-dwyer-headli...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Giants goal-attack Sophie Dwyer has been elev...</td>\n",
       "      <td>giant sophi dwyer elev diamond tour invite sen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>/news/2021-11-24/wbbl-brisbane-heat-vs-adelaid...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Adelaide Strikers spinner Amanda-Jade Welling...</td>\n",
       "      <td>adelaid striker spinner wellington produc best...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>/news/2021-11-25/23-under-23-a-league-women-pl...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Australia's top professional women's competit...</td>\n",
       "      <td>top profession competit long greenhous produc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>/news/2021-11-25/a-league-women-lisa-de-vanna-...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Matildas great Lisa De Vanna will chase anoth...</td>\n",
       "      <td>matilda great lisa de vanna chase anoth titl s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>/news/2021-11-25/afl-draft-live-blog-second-ro...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Fremantle wasted no time claiming Matt Johnso...</td>\n",
       "      <td>fremantl wast time claim matt johnson kick sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>/news/2021-11-25/australians-josh-giddey-patty...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Young Australian Josh Giddey has again flirte...</td>\n",
       "      <td>young australian josh giddey flirt creat nba b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>/news/2021-11-25/candice-warner-weighs-in-on-t...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Candice Warner says she is \"concerned\" about ...</td>\n",
       "      <td>candic warner say cricket stanc allow tim pain...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 uri article_category  \\\n",
       "0  /news/2021-11-24/afl-carlton-ceo-brian-cook-te...            sport   \n",
       "1  /news/2021-11-24/afl-national-draft-kangaroos-...            sport   \n",
       "2  /news/2021-11-24/shaun-murphy-amateurs-not-pla...            sport   \n",
       "3  /news/2021-11-24/teen-star-sophie-dwyer-headli...            sport   \n",
       "4  /news/2021-11-24/wbbl-brisbane-heat-vs-adelaid...            sport   \n",
       "5  /news/2021-11-25/23-under-23-a-league-women-pl...            sport   \n",
       "6  /news/2021-11-25/a-league-women-lisa-de-vanna-...            sport   \n",
       "7  /news/2021-11-25/afl-draft-live-blog-second-ro...            sport   \n",
       "8  /news/2021-11-25/australians-josh-giddey-patty...            sport   \n",
       "9  /news/2021-11-25/candice-warner-weighs-in-on-t...            sport   \n",
       "\n",
       "                            article_text_description  \\\n",
       "0   Carlton chief executive Brian Cook has tested...   \n",
       "1   Outstanding South Australian prospect Jason H...   \n",
       "2   Professional snooker player Shaun Murphy says...   \n",
       "3   Giants goal-attack Sophie Dwyer has been elev...   \n",
       "4   Adelaide Strikers spinner Amanda-Jade Welling...   \n",
       "5   Australia's top professional women's competit...   \n",
       "6   Matildas great Lisa De Vanna will chase anoth...   \n",
       "7   Fremantle wasted no time claiming Matt Johnso...   \n",
       "8   Young Australian Josh Giddey has again flirte...   \n",
       "9   Candice Warner says she is \"concerned\" about ...   \n",
       "\n",
       "                                        bag_of_words  \n",
       "0  carlton chief execut brian cook test posit for...  \n",
       "1  outstand south australian prospect jason selec...  \n",
       "2  profession snooker player shaun murphi say ama...  \n",
       "3  giant sophi dwyer elev diamond tour invite sen...  \n",
       "4  adelaid striker spinner wellington produc best...  \n",
       "5  top profession competit long greenhous produc ...  \n",
       "6  matilda great lisa de vanna chase anoth titl s...  \n",
       "7  fremantl wast time claim matt johnson kick sec...  \n",
       "8  young australian josh giddey flirt creat nba b...  \n",
       "9  candic warner say cricket stanc allow tim pain...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming, Lemmating and Cleaning Bag of Words\n",
    "\n",
    "def nltk_remove_punc_numeric(df_column):\n",
    "    # Function to remove punctuation and numeric values from bag of words column\n",
    "    df_column = df_column.split(' ')\n",
    "    output=[word.lower() for word in df_column if word.isalpha()]\n",
    "    return ' '.join(output)  \n",
    "    \n",
    "def nltk_stemming(df_column):\n",
    "    # Function to stem words in bag of words column\n",
    "    df_column = df_column.split(' ')\n",
    "    stemmer = PorterStemmer() \n",
    "    output = [stemmer.stem(word) for word in df_column]\n",
    "    return ' '.join(output) \n",
    "\n",
    "def nltk_lemmatize(df_column):\n",
    "    # Function to lemmatize words in bag of words column\n",
    "    df_column = df_column.split(' ')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    output = [lemmatizer.lemmatize(word) for word in df_column]\n",
    "    return ' '.join(output) \n",
    "            \n",
    "def nltk_remove_stopwords(df_column):\n",
    "    # Function to remove stopwords from bag of words column\n",
    "    df_column = df_column.split(' ')\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    output=[word.lower() for word in df_column if not word in stopWords]\n",
    "    return ' '.join(output)  \n",
    "\n",
    "def run_all_nltk_cleaning(df):    \n",
    "    # Function to run all NLTK cleaning\n",
    "    df_prepped = df\n",
    "    print('Removing Punctuation and Numbers...')\n",
    "    df_prepped['bag_of_words'] = df['bag_of_words'].apply(nltk_remove_punc_numeric)\n",
    "    print('Removing Stopwords...')\n",
    "    df_prepped['bag_of_words'] = df['bag_of_words'].apply(nltk_remove_stopwords)\n",
    "    print('Applying Lemmatizing...')\n",
    "    df_prepped['bag_of_words'] = df['bag_of_words'].apply(nltk_lemmatize)\n",
    "    print('Applying Stemming...')\n",
    "    df_prepped['bag_of_words'] = df['bag_of_words'].apply(nltk_stemming)\n",
    "    \n",
    "    return df_prepped\n",
    "\n",
    "articles_df  = run_all_nltk_cleaning(articles_df)\n",
    "articles_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Categorical Target Variable for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uri</th>\n",
       "      <th>article_category</th>\n",
       "      <th>article_text_description</th>\n",
       "      <th>bag_of_words</th>\n",
       "      <th>article_category_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>/news/2021-11-24/afl-carlton-ceo-brian-cook-te...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Carlton chief executive Brian Cook has tested...</td>\n",
       "      <td>carlton chief execut brian cook test posit for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>/news/2021-11-24/afl-national-draft-kangaroos-...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Outstanding South Australian prospect Jason H...</td>\n",
       "      <td>outstand south australian prospect jason selec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>/news/2021-11-24/shaun-murphy-amateurs-not-pla...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Professional snooker player Shaun Murphy says...</td>\n",
       "      <td>profession snooker player shaun murphi say ama...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>/news/2021-11-24/teen-star-sophie-dwyer-headli...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Giants goal-attack Sophie Dwyer has been elev...</td>\n",
       "      <td>giant sophi dwyer elev diamond tour invite sen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>/news/2021-11-24/wbbl-brisbane-heat-vs-adelaid...</td>\n",
       "      <td>sport</td>\n",
       "      <td>Adelaide Strikers spinner Amanda-Jade Welling...</td>\n",
       "      <td>adelaid striker spinner wellington produc best...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 uri article_category  \\\n",
       "0  /news/2021-11-24/afl-carlton-ceo-brian-cook-te...            sport   \n",
       "1  /news/2021-11-24/afl-national-draft-kangaroos-...            sport   \n",
       "2  /news/2021-11-24/shaun-murphy-amateurs-not-pla...            sport   \n",
       "3  /news/2021-11-24/teen-star-sophie-dwyer-headli...            sport   \n",
       "4  /news/2021-11-24/wbbl-brisbane-heat-vs-adelaid...            sport   \n",
       "\n",
       "                            article_text_description  \\\n",
       "0   Carlton chief executive Brian Cook has tested...   \n",
       "1   Outstanding South Australian prospect Jason H...   \n",
       "2   Professional snooker player Shaun Murphy says...   \n",
       "3   Giants goal-attack Sophie Dwyer has been elev...   \n",
       "4   Adelaide Strikers spinner Amanda-Jade Welling...   \n",
       "\n",
       "                                        bag_of_words  article_category_bin  \n",
       "0  carlton chief execut brian cook test posit for...                     1  \n",
       "1  outstand south australian prospect jason selec...                     1  \n",
       "2  profession snooker player shaun murphi say ama...                     1  \n",
       "3  giant sophi dwyer elev diamond tour invite sen...                     1  \n",
       "4  adelaid striker spinner wellington produc best...                     1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode 2 classes from 'Article Category' as Binary encoding\n",
    "articles_df['article_category'].astype('category')\n",
    "\n",
    "lb = preprocessing.LabelBinarizer() # Create binarizer\n",
    "\n",
    "# Fit binarizer to category variable, transfrom variable and store to new variable\n",
    "articles_df['article_category_bin'] = lb.fit_transform(articles_df['article_category'])\n",
    "\n",
    "articles_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228, 1000)\n",
      "(228,)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "tfidf_vec = TfidfVectorizer(max_features=1000, ngram_range=(1, 2)) \n",
    "\n",
    "# Fit and transform to 'bag of words' and convert to nd.array \n",
    "X = tfidf_vec.fit_transform(articles_df['bag_of_words']).toarray() # Fit and transform to 'bag of words' and convert to nd.array \n",
    "\n",
    "print(X.shape) # Show X shape\n",
    "\n",
    "#Create target variable as nd.array\n",
    "y = articles_df['article_category_bin'].values \n",
    "\n",
    "\n",
    "print(y.shape)# Show X shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split population in test and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=0)#, max_depth=2\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "classifier = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.61%\n",
      "Standard Deviation: 3.24%\n"
     ]
    }
   ],
   "source": [
    "# Perform 5 fold cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create 5 folds\n",
    "fold_accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 5)\n",
    "\n",
    "# 5 fold cross validation results\n",
    "print(\"Accuracy: {:.2f}%\".format(fold_accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f}%\".format(fold_accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0]\n",
      " [ 0 11]]\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Measure performance against test set\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0]\n",
      "[0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 0, 0, 11)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add visualisation\n",
    "\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Task 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP Task 2 will be a NER model to extra the names of entities in the corpus. A secondary step will be to match it to match ASX metadata using fuzzy wuzzy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = '/news/2021-11-26/shopping-black-friday-cyber-monday-deals-discounts-retail-sales/100653396'\n",
    "articles_df[articles_df['uri']==a].head(1)['article_text_description'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter business articles only\n",
    "business_articles_df = articles_df[articles_df['article_category']=='business'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract Potential Named Entities \n",
    "def get_potential_entities(df_row):\n",
    "    # Input is a whole dataframe row. Expects 'article_text_description' variable to be present\n",
    "    \n",
    "    potential_entities = set() # Output variable\n",
    "    document = df_row['article_text_description']\n",
    "    \n",
    "    # Get Parts of Speech using NLTK\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "    sentences = [nltk.pos_tag(sentence) for sentence in sentences]\n",
    "    \n",
    "    # Chunking\n",
    "    chunck_pos_regex = \"\"\"NP: {<NN.>*<NNP.?>+<NN.>*}\"\"\" # Identify proper nouns \n",
    "    chunck_parser = nltk.RegexpParser(chunck_pos_regex) # Create Parser\n",
    "    \n",
    "    # Loop through each sentence in text, parse chunks in sentence and store into temp variable\n",
    "    for sentence in sentences:\n",
    "        result = chunck_parser.parse(sentence)\n",
    "        \n",
    "        # Filter for proper noun chunks only\n",
    "        subtrees = result.subtrees(filter=lambda t: t.label() == 'NP')\n",
    "        named_words = None\n",
    "        for subtree in subtrees:        \n",
    "            named_words = [word[0] for word in subtree.leaves()]\n",
    "            named_words = ' '.join(named_words)\n",
    "        if named_words is not None: potential_entities.add(named_words)\n",
    "\n",
    "    return potential_entities\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "business_articles_df['potential_entities'] = business_articles_df.apply(get_potential_entities, axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uri</th>\n",
       "      <th>article_category</th>\n",
       "      <th>article_text_description</th>\n",
       "      <th>bag_of_words</th>\n",
       "      <th>article_category_bin</th>\n",
       "      <th>potential_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>/news/2021-11-26/nats-egypt-unveils-renovated-...</td>\n",
       "      <td>business</td>\n",
       "      <td>Egyptian authorities have unveiled a renovate...</td>\n",
       "      <td>egyptian author unveil renov ancient promenad ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{Thursday, BC, Cairo, Luxor, Nile, COVID-19, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>/news/2021-11-26/shopping-black-friday-cyber-m...</td>\n",
       "      <td>business</td>\n",
       "      <td>It used to be an American-only affair. The te...</td>\n",
       "      <td>use term black friday reportedli origin factor...</td>\n",
       "      <td>0</td>\n",
       "      <td>{Black Friday deals, Cyber Monday, Boxing Day,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>/news/2021-11-26/three-arrested-for-alleged-mo...</td>\n",
       "      <td>business</td>\n",
       "      <td>South Australia Police have charged two men a...</td>\n",
       "      <td>south australia polic charg two men woman drug...</td>\n",
       "      <td>0</td>\n",
       "      <td>{Adelaide Magistrates Court, Kings Park, SA, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>/news/2021-11-26/uranium-miner-vimy-mulga-rock...</td>\n",
       "      <td>business</td>\n",
       "      <td>The company developing Western Australia's fi...</td>\n",
       "      <td>compani develop western first uranium mine say...</td>\n",
       "      <td>0</td>\n",
       "      <td>{Kalgoorlie-Boulder, January, Western Australi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>/news/2021-11-27/government-pays-three-capes-w...</td>\n",
       "      <td>business</td>\n",
       "      <td>A commercial walking company in Tasmania has ...</td>\n",
       "      <td>commerci walk compani tasmania receiv hundr th...</td>\n",
       "      <td>0</td>\n",
       "      <td>{ABC, Parks, ABC News, Tasmania, State, Three ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  uri article_category  \\\n",
       "25  /news/2021-11-26/nats-egypt-unveils-renovated-...         business   \n",
       "29  /news/2021-11-26/shopping-black-friday-cyber-m...         business   \n",
       "30  /news/2021-11-26/three-arrested-for-alleged-mo...         business   \n",
       "31  /news/2021-11-26/uranium-miner-vimy-mulga-rock...         business   \n",
       "40  /news/2021-11-27/government-pays-three-capes-w...         business   \n",
       "\n",
       "                             article_text_description  \\\n",
       "25   Egyptian authorities have unveiled a renovate...   \n",
       "29   It used to be an American-only affair. The te...   \n",
       "30   South Australia Police have charged two men a...   \n",
       "31   The company developing Western Australia's fi...   \n",
       "40   A commercial walking company in Tasmania has ...   \n",
       "\n",
       "                                         bag_of_words  article_category_bin  \\\n",
       "25  egyptian author unveil renov ancient promenad ...                     0   \n",
       "29  use term black friday reportedli origin factor...                     0   \n",
       "30  south australia polic charg two men woman drug...                     0   \n",
       "31  compani develop western first uranium mine say...                     0   \n",
       "40  commerci walk compani tasmania receiv hundr th...                     0   \n",
       "\n",
       "                                   potential_entities  \n",
       "25  {Thursday, BC, Cairo, Luxor, Nile, COVID-19, C...  \n",
       "29  {Black Friday deals, Cyber Monday, Boxing Day,...  \n",
       "30  {Adelaide Magistrates Court, Kings Park, SA, S...  \n",
       "31  {Kalgoorlie-Boulder, January, Western Australi...  \n",
       "40  {ABC, Parks, ABC News, Tasmania, State, Three ...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "business_articles_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
